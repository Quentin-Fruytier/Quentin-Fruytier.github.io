<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Quentin Fruytier</title>

  <meta name="author" content="Quentin Fruytier">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/jpg" href="images/me2023.jpg">
  <style>
  div {
    opacity: 0.5;
  }
  </style>
  <style>
  #more {display: none;}
  </style>
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Quentin Fruytier</name>
                <p>
                    I am a PhD Candidate in Electrical and Computer Engineering (ECE) at the <a href="https://www.utexas.edu/">University of Texas at Austin</a>, where I am advised by <a href="https://sites.utexas.edu/mokhtari/">Prof. Aryan Mokhtari</a> and <a href="https://sites.utexas.edu/sanghavi/">Prof. Sujay Sanghavi</a>. My research focuses on <strong>Machine Learning</strong>, specifically at the intersection of <strong>optimization theory</strong>, <strong>representation learning</strong>, and <strong>latent variable models</strong>.
                </p>
                <p>
                    My work aims to build more efficient and robust large-scale models. My recently accepted paper, <a href="https://proceedings.mlr.press/v267/fruytier25a.html">Learning Mixtures of Experts with EM: A Mirror Descent Perspective</a> (ICML 2025), demonstrates that the Expectation-Maximization (EM) algorithm can significantly <strong>outperform standard optimizers like Adam</strong> for training Mixture of Experts (MoE) models. During my research internship at Interdigital, I developed novel solutions for model interoperability by creating a novel framework that allows for explicity distributional enforcement of the aggregate posterior, which resulted in a <strong>patent</strong>. We additionally submitted our findings as a paper to ICLR 2026 -- <a href="https://arxiv.org/abs/2510.11953"> Sculpting Latent Spaces with MMD: Disentanglement With Programmable Priors</a>.
                </p>
                <p>
                    I hold an MSc in Mathematics & Statistics where I was advised by <a href="https://www.mcgill.ca/mathstat/tim-hoheisel">Prof. Tim Hoheisel</a> and <a href="https://www.mcgill.ca/mathstat/abbas-khalili">Prof. Abbas Khalili</a> and a BSc in Joint Honours Mathematics & Computer Science from McGill University. This strong theoretical foundation, combined with hands-on experience from software engineering and data science internships, allows me to bridge the gap between AI theory and real-world application.
                </p>
              
              <p style="text-align:center">
                <a href="mailto:qfruytier@gmail.com">Contact</a>  &nbsp/&nbsp
                <a href="data/Resume_october_2025.pdf" target="_blank" rel="noopener noreferrer">Resume</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?view_op=list_works&hl=en&hl=en&user=NWlzhb8AAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/quentin-fruytier/">LinkedIn</a> &nbsp/&nbsp       
                <a href="https://github.com/Quentin-Fruytier">GitHub</a> <!-- &nbsp/&nbsp -->
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/me2023.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/me2023.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

<!-- Updates========================================================================================== -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Updates</heading>
              </td>
              </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <!--========================================================================================== -->
          <td>
            <ul>
              <li><b>Oct 2025: </b> New preprint: <a href="https://arxiv.org/abs/2510.11953">Sculpting Latent Spaces With MMD: Disentanglement With Programmable Priors</a> appeared on ArXiv!</li>
              <p></p>
              <li><b>Sept 2025: </b> Patent Filing: Filed a new patent "Methods For Latent Distribution Shaping Based Quantization, Interoperability, and Performance Monitoring" (Application No. 19/337202). </li>
              <p></p>
              <li><b>Aug 2025: </b> Internship Extension: Accepted offer to extend internship until December 2025!</li>
              <p></p>
              <li><b>May 2025: </b> Internship: Beginning summer internship <strong> AI/ML Researcher for Wireless</strong> at Interdigital AI Lab in Los Altos, California!</li>
              <p></p>
              <li><b>May 2025: </b> Publication: Excited to Announce that <a href="https://icml.cc/virtual/2025/poster/4360">Learning Mixture of Experts With MMD: A Mirror Descent Perspective</a> was accepted at ICML 2025.</li>
            </ul>
            <button onclick="myFunction()" id="myBtn">More</button>
            <p></p>
          </td>
        </tbody>
      </table>

        <script>
        function myFunction() {
          var dots = document.getElementById("dots");
          var moreText = document.getElementById("more");
          var btnText = document.getElementById("myBtn");

          if (dots.style.display === "none") {
            dots.style.display = "inline";
            btnText.innerHTML = "More"; 
            moreText.style.display = "none";
          } else {
            dots.style.display = "none";
            btnText.innerHTML = "Less"; 
            moreText.style.display = "inline";
          }
        }
        </script>


      
        <!-- Publications==========================================================================================-->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research Publications</heading>
            </td>
          </tr>
        </tbody></table>

        <!-- 2023==========================================================================================-->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Representation Learning</heading>
              </td>
            </tr>
          </tbody>
        </table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/SculptingLatentSpaces.png' style="width: 100%;">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <mark style="color:red"><b>NEW</b></mark> &nbsp 
              <a href="https://arxiv.org/abs/2510.11953"><papertitle>Sculpting Latent Spaces with MMD: Disentanglement With Programmable Priors</papertitle></a>
              <br>
              <strong>Quentin Fruytier</strong>, Akshay Malhotra, Shahab Hamidi-Rad, Aditya Sant, Aryan Mokhtari, and Sujay Sanghavi
              <br>
              <em>ArXiv</em>, 2025
              <br> 
              <!-- <a href="https://openreview.net/</a> &nbsp -->
              <a href="https://github.com/Quentin-Fruytier/Sculpting-Latent-Spaces-With-MMD">Project Page</a> &nbsp 
              <a href="data/SculptingLatentSpaces.pdf" target="_blank" rel="noopener noreferrer">PDF</a> &nbsp
              <a href="https://arxiv.org/abs/2510.11953">ArXiv</a> &nbsp
              <p></p>
              <p>
                We show that the standard KL-based regularizer in VAEs is an unreliable mechanism for learning disentangled representations. Our solution is the Programmable Prior Framework, a novel MMD-based method that explicitly engineers the latent space to achieve state-of-the-art disentanglement without the common reconstruction trade-off. To validate that our method learns mutually independent features, we also introduce the Latent Predictability Score (LPS), a new unsupervised metric for quantifying entanglement on large-scale datasets.
              </p>
            </td>
          </tr>

        <!-- 2022==========================================================================================-->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Optimization Theory</heading>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <!--==========================================================================================-->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/EMForMOE.png' style="width: 100%;">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openreview.net/forum?id=wjZcCbTvrU"><papertitle>Learning Mixtures of Experts With EM: A Mirror Descent Perspective</papertitle></a>
              <br>
              <strong>Quentin Fruytier</strong>, Aryan Mokhtari, and Sujay Sanghavi
              <br>
              <a href="https://icml.cc/virtual/2025/poster/43609">ICML 2025</a>
              <br>
              <a href="https://openreview.net/forum?id=wjZcCbTvrU">OpenReview</a> 
              &nbsp <a href="https://openreview.net/pdf?id=wjZcCbTvrU">PDF</a> 
              &nbsp <a href="https://arxiv.org/abs/2411.06056">ArXiv</a> 
              &nbsp <a href="data/ICML2025_EMMOE.pdf"> Slides </a> 
              &nbsp <a href="data/Poster__MOE_ICML2025.pdf">Poster</a>            
              <p></p>
              <p>We provide a theoretical analysis of the Expectation-Maximization (EM) algorithm for training Mixture of Experts (MoE) models. Our work connects EM to Mirror Descent to establish new convergence guarantees and shows through theory and experiments that EM can be a faster and more accurate alternative to standard gradient descent. </p>
            </td>
         </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/ReviewEM.png' style="width: 100%;">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=NWlzhb8AAAAJ&citation_for_view=NWlzhb8AAAAJ:u5HHmVD_uO8C"><papertitle>A Review of the Expectation-Maximization Algorithm and its Applications to Mixture Models</papertitle></a>
              <br>
              <strong>Quentin Fruytier</strong>
              <br>
              <em>MSc Thesis</em>, 2023
              <br>
              <a href="https://www.proquest.com/openview/23a8a8ef71f73a1e3342fb78a9681876/1?pq-origsite=gscholar&cbl=18750&diss=y">OpenView</a>
              <p></p>
              <p>This thesis provides a comprehensive review of the Expectation-Maximization (EM) algorithm, a powerful tool for parameter estimation in models with latent variables. Spanning from its foundational concepts in the 1970s to its modern applications, this work covers the algorithm's convergence properties and practical uses in mixture models, serving as a valuable resource for researchers. </p>
            </td>
          </tr>
          
        </tbody></table>
         <!--==========================================================================================-->

         <!-- 2021==========================================================================================-->
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Neural Network Learning Theory &amp Pattern Recognition</heading>
          </td>
        </tr>
      </tbody></table> -->
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Other Projects</heading>
            </td>
          </tr>
        </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/GlickoElo.png' style="width: 100%;">
          </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <!-- <mark style="color:red"><b>NEW</b></mark> &nbsp --> 
                  <a href="data/Online_Learning_Project__Rating_Problem.pdf"><papertitle>A Case Against Using Elo or Glicko Algorithms for Rating Players in n vs n Games</papertitle></a>
                    <br>
                    <strong>Quentin Fruytier</strong>
                    <br>
                    <br>
                    <a href="data/Online_Learning_Project__Rating_Problem.pdf">PDF</a> 
                    <p></p>
                    <p>This project investigates the failure of traditional rating systems like Elo and Glicko in team-based (n-vs-n) esports. Our simulations reveal a clear and drastic decrease in accuracy as team sizes grow beyond 1v1, highlighting the inability of these algorithms to account for individual performance gaps. We advocate for a novel system that incorporates in-game performance metrics to provide more accurate and responsive player ratings.</p>
                </td>
        </tr>
      <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src='images/ReviewEM.png' style="width: 100%;">
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="AI_for_Traffic_Prediction"><papertitle>AI For Traffic Prediction</papertitle></a>
        <br>
        <strong>Quentin Fruytier</strong>
        <br>
        <br>
        <a href="AI_for_Traffic_Prediction">PDF</a> 
        <p></p>
        <p>This project analyzes Deep Learning methods for traffic prediction, a key challenge due to complex spatial and temporal patterns. We take a deep dive into the state-of-the-art DCRNN model, investigating how its feature space dimension impacts performance on the METR-LA dataset and proposing specific architectural improvements to enhance prediction accuracy.
        </p>
      </td>
      </tr>
    </tbody></table>
    

           
         

 <!-- Patents==========================================================================================-->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Patent</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/SculptingLatentSpaces.png' style="width: 100%;">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Methods For Latent Distribution Shaping Based Quantization, Interoperability, and Performance Monitoring</papertitle></a>
              <br>
              Akshay Malhotra, <strong>Quentin Fruytier</strong>
              <br>
              <em>Los Althos, California</em>, 2025
              <br>
              Patent No. *****,  US Patent Application No. 19/337202
              <br>
              <p></p>
              <p>The present application patent protects a newly invented framework for deliberate sculpting of the latent space with MMD that achieves learning desired aggregate posterior distributions for the latent space. Targetted applications include Model Interoperability, Quantization, and Performance Monitoring.</p>
            </td>
          </tr>
        </tbody></table>
    	
<!--==========================================================================================-->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:45%;vertical-align:middle">
            </td>
            <td style="padding:20px;width:55%;vertical-align:middle">
              <!-- <div> Thanks to <a href="https://jonbarron.info/">Jon Barron</a> for the template.</div> -->
              <a href="https://jonbarron.info/">Website Template</a>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
